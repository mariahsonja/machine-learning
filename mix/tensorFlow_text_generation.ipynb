{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing packages & libraries\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get reference corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading and processing data\n",
    "data = open('./data/irish-lyrics.txt').read()\n",
    "corpus = data.lower().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2690\n"
     ]
    }
   ],
   "source": [
    "# defining tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "# print(tokenizer.word_index)\n",
    "print(total_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing data\n",
    "input_sequences = []\n",
    "for line in corpus:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)\n",
    "\n",
    "# padding sequences \n",
    "max_sequence_len = max([len(x) for x in input_sequences])\n",
    "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "\n",
    "# creating predictors and label\n",
    "xs, labels = input_sequences[:,:-1],input_sequences[:,-1]\n",
    "\n",
    "ys = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(total_words, 100, input_length=max_sequence_len-1),\n",
    "    tf.keras.layers.Bidirectional(LSTM(150)),\n",
    "    tf.keras.layers.Dense(total_words, activation = 'softmax'),\n",
    "])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer= 'adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12038 samples\n",
      "Epoch 1/10\n",
      "12038/12038 [==============================] - 10s 855us/sample - loss: 6.7406 - accuracy: 0.0654\n",
      "Epoch 2/10\n",
      "12038/12038 [==============================] - 8s 705us/sample - loss: 6.2529 - accuracy: 0.0737\n",
      "Epoch 3/10\n",
      "12038/12038 [==============================] - 9s 714us/sample - loss: 5.9852 - accuracy: 0.0835\n",
      "Epoch 4/10\n",
      "12038/12038 [==============================] - 9s 711us/sample - loss: 5.6800 - accuracy: 0.0998\n",
      "Epoch 5/10\n",
      "12038/12038 [==============================] - 9s 708us/sample - loss: 5.3554 - accuracy: 0.1146\n",
      "Epoch 6/10\n",
      "12038/12038 [==============================] - 9s 714us/sample - loss: 5.0215 - accuracy: 0.1334\n",
      "Epoch 7/10\n",
      "12038/12038 [==============================] - 9s 708us/sample - loss: 4.6793 - accuracy: 0.1502\n",
      "Epoch 8/10\n",
      "12038/12038 [==============================] - 8s 700us/sample - loss: 4.3419 - accuracy: 0.1710\n",
      "Epoch 9/10\n",
      "12038/12038 [==============================] - 9s 714us/sample - loss: 4.0007 - accuracy: 0.2043\n",
      "Epoch 10/10\n",
      "12038/12038 [==============================] - 9s 717us/sample - loss: 3.6719 - accuracy: 0.2514\n"
     ]
    }
   ],
   "source": [
    "# training model\n",
    "history = model.fit(xs, ys, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate text sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I too am a human being and I was seen in the stony sea of the upwards wind of doneen sends by the sea they treads the upwards church dwell near fulfill you more young young young young more young more young more grey our hand and our hat and they did stand and shrill they did stand in side and tory ghosts and stainless they did say me now dhu easy and the wind of spancil hill and tory ghosts and goblins lingers now now writin to go street i sat side by corporal casey by spancil hill today today by the clay clay turning treads the\n"
     ]
    }
   ],
   "source": [
    "# generating text\n",
    "seed_text = \"I too am a human being and I\"\n",
    "# seed_text = \"I've got a bad feeling about this\"\n",
    "next_words = 100\n",
    "  \n",
    "for _ in range(next_words):\n",
    "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "    predicted = model.predict_classes(token_list, verbose=0)\n",
    "    output_word = \"\"\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == predicted:\n",
    "            output_word = word\n",
    "            break\n",
    "    seed_text += \" \" + output_word\n",
    "print(seed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
